{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/.local/lib/python3.9/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/.local/lib/python3.9/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/.local/lib/python3.9/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.11.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib64/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/.local/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-0.29.3\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# !pip3 install transformers\n",
    "# !pip3 install torch\n",
    "!pip3 install accelerate\n",
    "\n",
    "from utils import load_config, set_environment_variables, num_tokens_from_messages, get_git_files, get_data_files\n",
    "import sys\n",
    "import os\n",
    "config       = load_config('config.yaml')\n",
    "set_environment_variables(config)\n",
    "ACCESS_TOKEN = os.environ['GIT_ACCESS_TOKEN']\n",
    "sys.path.append(\"/database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import get_documentation_by_url, put_new_repository_documentation, get_file_documentation, delete_documentation_by_url, get_status, get_status_by_file, external_json_to_repo_overview_output, get_all_urls_in_db\n",
    "from repo_processor import process_file, parallel_process_files, download_and_process_repo_url, get_repo_overview\n",
    "from OverviewChain import OverviewParser, ConfluenceOverviewChain\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain.document_loaders import GithubFileLoader\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from ConfluenceChain import ConfluenceChain, Parser\n",
    "from IPython.display import display, Markdown\n",
    "from pymongo import MongoClient\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a pirate chatbot who always responds in pirate speak!\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     15\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     16\u001b[0m ]\n\u001b[1;32m     18\u001b[0m prompt \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     19\u001b[0m         messages, \n\u001b[1;32m     20\u001b[0m         tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     21\u001b[0m         add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/__init__.py:906\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    905\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 906\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    917\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/base.py:283\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    285\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:3086\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3083\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3084\u001b[0m         )\n\u001b[1;32m   3085\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 3086\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   3087\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3088\u001b[0m         )\n\u001b[1;32m   3090\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[0;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url              = \"https://github.com/dbhatia00/documentation-generation/\" #\"https://github.com/Adarsh9616/Electricity_Billing_System\"\n",
    "repo_url              = \"https://github.com/thuml/Time-Series-Library\"\n",
    "supported_languages   = ['python', 'java', 'javascript']\n",
    "\n",
    "# data_dict             = download_and_process_repo_url(repo_url, supported_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Repository URL successfully enqueued: https://github.com/thuml/Time-Series-Library'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_to_process_repo = f\"https://bjxdbdicckttmzhrhnpl342k2q0pcthx.lambda-url.us-east-1.on.aws/?repo_url={repo_url}\"\n",
    "response            = requests.get(url_to_process_repo)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add code for context lengths greater than 32K tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repository_url': 'https://github.com/thuml/Time-Series-Library',\n",
       " 'overall_status': 'Completed',\n",
       " 'file_level_status': {'exp/..init...py': 'Completed',\n",
       "  'data.provider/..init...py': 'Completed',\n",
       "  'layers/..init...py': 'Completed',\n",
       "  'models/ETSformer.py': 'Completed',\n",
       "  'layers/FourierCorrelation.py': 'Completed',\n",
       "  'layers/Conv.Blocks.py': 'Completed',\n",
       "  'layers/Crossformer.EncDec.py': 'Completed',\n",
       "  'layers/Transformer.EncDec.py': 'Completed',\n",
       "  'exp/exp.basic.py': 'Completed',\n",
       "  'layers/Autoformer.EncDec.py': 'Completed',\n",
       "  'run.py': 'Completed',\n",
       "  'data.provider/m4.py': 'Completed',\n",
       "  'data.provider/data.factory.py': 'Completed',\n",
       "  'models/FiLM.py': 'Completed',\n",
       "  'models/FreTS.py': 'Completed',\n",
       "  'models/Crossformer.py': 'Completed',\n",
       "  'layers/StandardNorm.py': 'Completed',\n",
       "  'exp/exp.anomaly.detection.py': 'Completed',\n",
       "  'models/FEDformer.py': 'Completed',\n",
       "  'exp/exp.short.term.forecasting.py': 'Completed',\n",
       "  'models/Koopa.py': 'Completed',\n",
       "  'models/..init...py': 'Completed',\n",
       "  'utils/..init...py': 'Completed',\n",
       "  'data.provider/uea.py': 'Completed',\n",
       "  'models/Mamba.py': 'Completed',\n",
       "  'layers/SelfAttention.Family.py': 'Completed',\n",
       "  'exp/exp.classification.py': 'Completed',\n",
       "  'exp/exp.long.term.forecasting.py': 'Completed',\n",
       "  'layers/AutoCorrelation.py': 'Completed',\n",
       "  'models/Autoformer.py': 'Completed',\n",
       "  'models/LightTS.py': 'Completed',\n",
       "  'models/Informer.py': 'Completed',\n",
       "  'models/TSMixer.py': 'Completed',\n",
       "  'models/PatchTST.py': 'Completed',\n",
       "  'exp/exp.imputation.py': 'Completed',\n",
       "  'layers/Pyraformer.EncDec.py': 'Completed',\n",
       "  'layers/ETSformer.EncDec.py': 'Completed',\n",
       "  'layers/Embed.py': 'Completed',\n",
       "  'models/TimeMixer.py': 'Completed',\n",
       "  'models/Nonstationary.Transformer.py': 'Completed',\n",
       "  'utils/print.args.py': 'Completed',\n",
       "  'layers/MultiWaveletCorrelation.py': 'Completed',\n",
       "  'models/TiDE.py': 'Completed',\n",
       "  'utils/masking.py': 'Completed',\n",
       "  'models/iTransformer.py': 'Completed',\n",
       "  'models/Reformer.py': 'Completed',\n",
       "  'models/MambaSimple.py': 'Completed',\n",
       "  'models/DLinear.py': 'Completed',\n",
       "  'models/SegRNN.py': 'Completed',\n",
       "  'data.provider/data.loader.py': 'Completed',\n",
       "  'utils/metrics.py': 'Completed',\n",
       "  'models/Pyraformer.py': 'Completed',\n",
       "  'utils/losses.py': 'Completed',\n",
       "  'models/Transformer.py': 'Completed',\n",
       "  'utils/tools.py': 'Completed',\n",
       "  'models/TimesNet.py': 'Completed',\n",
       "  'models/MICN.py': 'Completed',\n",
       "  'utils/m4.summary.py': 'Completed',\n",
       "  'utils/timefeatures.py': 'Completed',\n",
       "  'repo-overview-data': 'Completed'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "status_url = get_status(repo_url)\n",
    "# get_status_by_file(repo_url, file_name)\n",
    "status_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = get_documentation_by_url(repo_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## This repository focuses on time series analysis, offering a comprehensive library for tasks such as forecasting, imputation, anomaly detection, and classification. It incorporates advanced neural network models and techniques like Fast Fourier Transform, Inception blocks, and Transformer architectures to process and predict time series data efficiently."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Functionalities"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Key Functionalities"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Forecasting**: Generates future values based on historical time series data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Imputation**: Fills in missing values in time series datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Anomaly Detection**: Identifies unusual patterns that do not conform to expected behavior."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Classification**: Categorizes time series data into predefined groups."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Project Components"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Main Components"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Data Preprocessing**: Includes utilities for loading, normalizing, and preprocessing time series data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Model Training**: Facilitates the training of various neural network models on time series datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Evaluation Metrics**: Provides a suite of functions to evaluate model performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Visualization**: Supports the visualization of time series data and model predictions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Database Components"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Components"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Dataset Loaders**: Custom loaders for handling different time series datasets such as ETT, M4, and UEA."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Data Handlers**: Utilities for segmenting datasets into training, validation, and testing sets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Tech Stack"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Technology Stack"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **PyTorch**: The primary deep learning library used for model creation and training."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **NumPy**: Utilized for numerical operations and transformations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Pandas**: Used for data manipulation and analysis."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Matplotlib**: For plotting and visualizing time series data and results."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def display_repo_overview_in_md(repo_overview_data):\n",
    "    display(Markdown(f\"## {repo_overview_data.overall_summary}\"))\n",
    "    display(Markdown(f\"### Functionalities\"))\n",
    "    display(Markdown(f\"#### Key Functionalities\"))\n",
    "    for key, value in repo_overview_data.functionalities.items():\n",
    "        display(Markdown(f\"- **{key}**: {value}\"))\n",
    "    display(Markdown(f\"### Project Components\"))\n",
    "    display(Markdown(f\"#### Main Components\"))\n",
    "    for key, value in repo_overview_data.project_components.items():\n",
    "        display(Markdown(f\"- **{key}**: {value}\"))\n",
    "    display(Markdown(f\"### Database Components\"))\n",
    "    display(Markdown(f\"#### Components\"))\n",
    "    for key, value in repo_overview_data.database_components.items():\n",
    "        display(Markdown(f\"- **{key}**: {value}\"))\n",
    "    display(Markdown(f\"### Tech Stack\"))\n",
    "    display(Markdown(f\"#### Technology Stack\"))\n",
    "    for key, value in repo_overview_data.tech_stack.items():\n",
    "        display(Markdown(f\"- **{key}**: {value}\"))\n",
    "        \n",
    "display_repo_overview_in_md(docs.repo_overview_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PackageDetail(BaseModel):\n",
    "#     \"\"\"\n",
    "#     Represents details of a package used in a file.\n",
    "\n",
    "#     Attributes:\n",
    "#     - usage: How the package is used in the file.\n",
    "#     - description: Description of the package.\n",
    "#     \"\"\"\n",
    "#     usage: str = Field(description=\"How the package is used in the file\")\n",
    "#     description: str = Field(description=\"Description of the package\")\n",
    "\n",
    "# class FunctionDetail(BaseModel):\n",
    "#     \"\"\"\n",
    "#     Represents details of a function defined in a file.\n",
    "\n",
    "#     Attributes:\n",
    "#     - name: Name of the function.\n",
    "#     - description: Description of what the function does.\n",
    "#     - class_declaration: Declaration of the class to which the function belongs. Should include everything from class to function.\n",
    "#     - additional_details: Additional information about the function.\n",
    "#     \"\"\"\n",
    "#     name: str = Field(..., description=\"Name of the function\")\n",
    "#     description: str = Field(..., description=\"Description of what the function does\")\n",
    "#     class_declaration: str = Field(description=\"Declaration of the class to which the function belongs. Should include everything from class to function.\", default=\"\")\n",
    "#     additional_details: str = Field(description=\"Additional information about the function\", default=\"\")\n",
    "\n",
    "# class FileConfluenceOutput(BaseModel):\n",
    "#     \"\"\"\n",
    "#     Represents a file in a repository with its details.\n",
    "\n",
    "#     Attributes:\n",
    "#     - file_path: Path of the file.\n",
    "#     - overall_summary: Overall summary of the file.\n",
    "#     - packages: Packages used in the file with their details.\n",
    "#     - functions: Functions defined in the file with their details.\n",
    "#     \"\"\"\n",
    "#     file_path: str = Field(..., description=\"Path of the file\")\n",
    "#     overall_summary: str = Field(description=\"Overall summary of the file\", default=\"\")\n",
    "#     packages: dict[str, PackageDetail] = Field(description=\"Packages used in the file with their details\")\n",
    "#     functions: dict[str, FunctionDetail] = Field(description=\"Functions defined in the file with their details\")\n",
    "#     confluence_page_id: str = Field(description=\"Confluence page ID of the file\", default=\"\")\n",
    "\n",
    "def display_file_output_in_md(file_output):\n",
    "    display(Markdown(f\"## {file_output.file_path}\"))\n",
    "    display(Markdown(f\"### Overall Summary\"))\n",
    "    display(Markdown(f\"{file_output.overall_summary}\"))\n",
    "    display(Markdown(f\"### Packages\"))\n",
    "    display(Markdown(f\"#### Packages Used\"))\n",
    "    for key, value in file_output.packages.items():\n",
    "        display(Markdown(f\"- **{key}**: {value.usage} - {value.description}\"))\n",
    "    display(Markdown(f\"### Functions\"))\n",
    "    display(Markdown(f\"#### Functions Defined\"))\n",
    "    for key, value in file_output.functions.items():\n",
    "        display(Markdown(f\"- **{key}**: {value.name} - {value.description}\"))\n",
    "        if value.class_declaration:\n",
    "            display(Markdown(f\"  - **Class Declaration for Function**: {value.class_declaration if value.class_declaration else 'None'}\"))\n",
    "        if value.additional_details:\n",
    "            display(Markdown(f\"  - **Additional Details**: {value.additional_details if value.additional_details else 'None'}\"))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## layers/Autoformer.EncDec.py"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Overall Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The file defines a series of PyTorch modules specifically designed for an Autoformer architecture, which is used for time series forecasting. It includes custom layer normalization, moving average blocks for trend highlighting, series decomposition blocks for extracting seasonal and trend components, and both encoder and decoder layers that incorporate attention mechanisms and convolutional layers for processing time series data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Packages"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Packages Used"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **torch**: Used for creating neural network modules, performing tensor operations, and applying functions like mean and concatenation. - PyTorch is an open-source machine learning library used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **torch.nn**: Utilized for building neural network layers and modules such as LayerNorm, Conv1d, AvgPool1d, ModuleList, and Dropout. - A subpackage of PyTorch that provides modules and classes to help create neural networks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **torch.nn.functional**: Applied for activation functions like ReLU and GELU. - A functional interface containing typical operations used for building neural networks, such as convolutional operations, activation functions, and loss functions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Functions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Functions Defined"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **my_Layernorm**: my_Layernorm - Special designed layernorm for the seasonal part of the time series."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "  - **Class Declaration for Function**: class my_Layernorm(nn.Module):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **moving_avg**: moving_avg - Moving average block to highlight the trend of time series."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "  - **Class Declaration for Function**: class moving_avg(nn.Module):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **series_decomp**: series_decomp - Series decomposition block for extracting and removing the moving average from the series."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "  - **Class Declaration for Function**: class series_decomp(nn.Module):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **series_decomp_multi**: series_decomp_multi - Multiple series decomposition block from FEDformer, applying multiple decompositions based on different kernel sizes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "  - **Class Declaration for Function**: class series_decomp_multi(nn.Module):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **EncoderLayer**: EncoderLayer - Autoformer encoder layer with the progressive decomposition architecture, incorporating attention and convolutional operations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "  - **Class Declaration for Function**: class EncoderLayer(nn.Module):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Encoder**: Encoder - Autoformer encoder that sequences multiple encoder layers and applies normalization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "  - **Class Declaration for Function**: class Encoder(nn.Module):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **DecoderLayer**: DecoderLayer - Autoformer decoder layer with the progressive decomposition architecture, similar to the encoder but includes cross-attention for processing encoder outputs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "  - **Class Declaration for Function**: class DecoderLayer(nn.Module):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Decoder**: Decoder - Autoformer decoder that sequences multiple decoder layers, applies normalization, and optionally a projection layer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "  - **Class Declaration for Function**: class Decoder(nn.Module):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs.files\n",
    "list_doc_files = list(docs.files.values())\n",
    "display_file_output_in_md(list_doc_files[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/thuml/Time-Series-Library/',\n",
       " 'https://github.com/dbhatia00/MonteHall',\n",
       " 'https://github.com/ajaye2/lumnisfactors-python-api',\n",
       " 'https://github.com/calmturtle124/react-studio',\n",
       " 'https://github.com/MadaniKK/api_dataschema',\n",
       " 'https://github.com/dengyixinliliow/bouncingBall',\n",
       " 'https://github.com/calmturtle124/YueqiTestRepo',\n",
       " 'https://github.com/calmturtle124/NewTestRepo',\n",
       " 'https://github.com/calmturtle124/NewTestRepo2',\n",
       " 'https://github.com/calmturtle124/NewTestRepo3',\n",
       " 'https://github.com/dbhatia00/NeuronSimulation',\n",
       " 'https://github.com/ajaye2/lumnisfactors-python-api/',\n",
       " 'https://github.com/Adarsh9616/Electricity_Billing_System',\n",
       " 'https://github.com/dbhatia00/documentation-generation/']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_urls_in_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# sqs       = boto3.client('sqs', 'us-east-1')\n",
    "# queue_url = 'https://sqs.us-east-1.amazonaws.com/018192622412/doc-gen'\n",
    "# response  = sqs.send_message(\n",
    "#     QueueUrl=queue_url,\n",
    "#     MessageBody=str(\"https://github.com/Adarsh9616/Electricity_Billing_System/\")\n",
    "# )\n",
    "\n",
    "# \"\"\" or \"\"\"\n",
    "\n",
    "# https://bjxdbdicckttmzhrhnpl342k2q0pcthx.lambda-url.us-east-1.on.aws/?repo_url=https://github.com/Adarsh9616/Electricity_Billing_System/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = sqs.receive_message(\n",
    "#     QueueUrl=queue_url,\n",
    "#     MaxNumberOfMessages=1,\n",
    "#     WaitTimeSeconds=1 # Long polling\n",
    "# )\n",
    "\n",
    "# messages = response.get('Messages', [])\n",
    "# print(messages)\n",
    "# while len(messages) != 0:\n",
    "#     response = sqs.receive_message(\n",
    "#         QueueUrl=queue_url,\n",
    "#         MaxNumberOfMessages=1,\n",
    "#         WaitTimeSeconds=1 # Long polling\n",
    "#     )\n",
    "\n",
    "#     messages = response.get('Messages', [])\n",
    "#     print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 0, 'electionId': ObjectId('7fffffff000000000000013b'), 'opTime': {'ts': Timestamp(1713840614, 40), 't': 315}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1713840614, 40), 'signature': {'hash': b\"\\xa3%<\\x0c#F\\xce\\xd2\\x848\\xf1\\x97C\\x1fJ\\xe4\\x96/*'\", 'keyId': 7313275603581403138}}, 'operationTime': Timestamp(1713840614, 40)}, acknowledged=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete_documentation_by_url(repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_of_repo = repo_url.split(\"/\")[-2]\n",
    "# res          = get_repo_overview(name_of_repo, str(docs.files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-interpreter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
